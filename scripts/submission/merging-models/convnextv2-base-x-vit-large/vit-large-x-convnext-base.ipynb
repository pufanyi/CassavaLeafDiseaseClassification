{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5865348b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-26T03:12:46.015250Z",
     "iopub.status.busy": "2024-10-26T03:12:46.014903Z",
     "iopub.status.idle": "2024-10-26T03:13:04.740502Z",
     "shell.execute_reply": "2024-10-26T03:13:04.739352Z"
    },
    "papermill": {
     "duration": 18.734747,
     "end_time": "2024-10-26T03:13:04.742991",
     "exception": false,
     "start_time": "2024-10-26T03:12:46.008244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import PIL\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import Compose, Normalize, Resize, CenterCrop, ToTensor\n",
    "\n",
    "id2label = {\n",
    "    0: \"Cassava Bacterial Blight (CBB)\",\n",
    "    1: \"Cassava Brown Streak Disease (CBSD)\",\n",
    "    2: \"Cassava Green Mottle (CGM)\",\n",
    "    3: \"Cassava Mosaic Disease (CMD)\",\n",
    "    4: \"Healthy\",\n",
    "}\n",
    "label2id = {\n",
    "    \"Cassava Bacterial Blight (CBB)\": 0,\n",
    "    \"Cassava Brown Streak Disease (CBSD)\": 1,\n",
    "    \"Cassava Green Mottle (CGM)\": 2,\n",
    "    \"Cassava Mosaic Disease (CMD)\": 3,\n",
    "    \"Healthy\": 4,\n",
    "}\n",
    "\n",
    "folder = Path(\"/kaggle/input/cassava-leaf-disease-classification/test_images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f1fe71",
   "metadata": {
    "papermill": {
     "duration": 0.004504,
     "end_time": "2024-10-26T03:13:04.752675",
     "exception": false,
     "start_time": "2024-10-26T03:13:04.748171",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ViT full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08e96416",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-26T03:13:04.763715Z",
     "iopub.status.busy": "2024-10-26T03:13:04.763054Z",
     "iopub.status.idle": "2024-10-26T03:13:08.845837Z",
     "shell.execute_reply": "2024-10-26T03:13:08.844986Z"
    },
    "papermill": {
     "duration": 4.090647,
     "end_time": "2024-10-26T03:13:08.848155",
     "exception": false,
     "start_time": "2024-10-26T03:13:04.757508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = \"/kaggle/input/sc4000-vit-large/models\"\n",
    "\n",
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    model_path,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True,\n",
    ")\n",
    "image_processor = AutoImageProcessor.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b121c416",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-26T03:13:08.859490Z",
     "iopub.status.busy": "2024-10-26T03:13:08.858797Z",
     "iopub.status.idle": "2024-10-26T03:13:08.867686Z",
     "shell.execute_reply": "2024-10-26T03:13:08.866814Z"
    },
    "papermill": {
     "duration": 0.016387,
     "end_time": "2024-10-26T03:13:08.869498",
     "exception": false,
     "start_time": "2024-10-26T03:13:08.853111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CassavaDatasetViT(Dataset):\n",
    "    def __init__(self, folder, image_processor):\n",
    "        self.folder = folder\n",
    "        self.image_processor = image_processor\n",
    "        self.image_paths = list(folder.glob(\"*\"))\n",
    "        self.image_mean, self.image_std = (\n",
    "            self.image_processor.image_mean,\n",
    "            self.image_processor.image_std,\n",
    "        )\n",
    "        size = self.image_processor.size[\"height\"]\n",
    "        normalize = Normalize(mean=self.image_mean, std=self.image_std)\n",
    "        self.test_transforms = Compose(\n",
    "            [\n",
    "                Resize(size),\n",
    "                CenterCrop(size),\n",
    "                ToTensor(),\n",
    "                normalize,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        with PIL.Image.open(image_path) as image:\n",
    "            inputs = self.test_transforms(image.convert(\"RGB\"))\n",
    "        return inputs, image_path.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcbec6e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-26T03:13:08.881161Z",
     "iopub.status.busy": "2024-10-26T03:13:08.880559Z",
     "iopub.status.idle": "2024-10-26T03:13:22.334271Z",
     "shell.execute_reply": "2024-10-26T03:13:22.333468Z"
    },
    "papermill": {
     "duration": 13.461473,
     "end_time": "2024-10-26T03:13:22.336585",
     "exception": false,
     "start_time": "2024-10-26T03:13:08.875112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vit_outputs = []\n",
    "\n",
    "dataset = CassavaDatasetViT(folder, image_processor)\n",
    "dataloader = DataLoader(dataset, batch_size=16)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch, image_names in dataloader:\n",
    "        outputs = model(batch.to(device))\n",
    "        probabilities = F.softmax(outputs.logits, dim=-1).cpu().numpy()\n",
    "\n",
    "        vit_outputs.extend(\n",
    "            {\"image_id\": image_name, \"output\": output}\n",
    "            for image_name, output in zip(image_names, probabilities)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b554bb",
   "metadata": {
    "papermill": {
     "duration": 0.004433,
     "end_time": "2024-10-26T03:13:22.345969",
     "exception": false,
     "start_time": "2024-10-26T03:13:22.341536",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ConvNeXt-V2 Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e07529e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-26T03:13:22.356876Z",
     "iopub.status.busy": "2024-10-26T03:13:22.356116Z",
     "iopub.status.idle": "2024-10-26T03:13:23.858159Z",
     "shell.execute_reply": "2024-10-26T03:13:23.857322Z"
    },
    "papermill": {
     "duration": 1.509708,
     "end_time": "2024-10-26T03:13:23.860363",
     "exception": false,
     "start_time": "2024-10-26T03:13:22.350655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = \"/kaggle/input/sc4000-convnext-v2-base/models\"\n",
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    model_path,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True,\n",
    ")\n",
    "image_processor = AutoImageProcessor.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27bf8278",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-26T03:13:23.871048Z",
     "iopub.status.busy": "2024-10-26T03:13:23.870762Z",
     "iopub.status.idle": "2024-10-26T03:13:23.878692Z",
     "shell.execute_reply": "2024-10-26T03:13:23.877831Z"
    },
    "papermill": {
     "duration": 0.015397,
     "end_time": "2024-10-26T03:13:23.880603",
     "exception": false,
     "start_time": "2024-10-26T03:13:23.865206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CassavaDatasetConvNeXtV2(Dataset):\n",
    "    def __init__(self, folder, image_processor):\n",
    "        self.folder = folder\n",
    "        self.image_processor = image_processor\n",
    "        self.image_paths = list(folder.glob(\"*\"))\n",
    "        self.image_mean, self.image_std = (\n",
    "            self.image_processor.image_mean,\n",
    "            self.image_processor.image_std,\n",
    "        )\n",
    "        size = self.image_processor.size[\"shortest_edge\"]\n",
    "        normalize = Normalize(mean=self.image_mean, std=self.image_std)\n",
    "        self.test_transforms = Compose(\n",
    "            [\n",
    "                Resize(size),\n",
    "                CenterCrop(size),\n",
    "                ToTensor(),\n",
    "                normalize,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        with PIL.Image.open(image_path) as image:\n",
    "            inputs = self.test_transforms(image.convert(\"RGB\"))\n",
    "        return inputs, image_path.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15c655d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-26T03:13:23.890994Z",
     "iopub.status.busy": "2024-10-26T03:13:23.890706Z",
     "iopub.status.idle": "2024-10-26T03:13:27.841056Z",
     "shell.execute_reply": "2024-10-26T03:13:27.840108Z"
    },
    "papermill": {
     "duration": 3.958171,
     "end_time": "2024-10-26T03:13:27.843452",
     "exception": false,
     "start_time": "2024-10-26T03:13:23.885281",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "convnext_outputs = []\n",
    "\n",
    "dataset = CassavaDatasetConvNeXtV2(folder, image_processor)\n",
    "dataloader = DataLoader(dataset, batch_size=16)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch, image_names in dataloader:\n",
    "        outputs = model(batch.to(device))\n",
    "        # predictions = outputs.logits.argmax(dim=-1).cpu().numpy()\n",
    "        probabilities = F.softmax(outputs.logits, dim=-1).cpu().numpy()\n",
    "\n",
    "        convnext_outputs.extend(\n",
    "            {\"image_id\": image_name, \"output\": output}\n",
    "            for image_name, output in zip(image_names, probabilities)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0e3229",
   "metadata": {
    "papermill": {
     "duration": 0.004648,
     "end_time": "2024-10-26T03:13:27.853218",
     "exception": false,
     "start_time": "2024-10-26T03:13:27.848570",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65194e27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-26T03:13:27.863748Z",
     "iopub.status.busy": "2024-10-26T03:13:27.863385Z",
     "iopub.status.idle": "2024-10-26T03:13:27.867927Z",
     "shell.execute_reply": "2024-10-26T03:13:27.867133Z"
    },
    "papermill": {
     "duration": 0.012005,
     "end_time": "2024-10-26T03:13:27.869866",
     "exception": false,
     "start_time": "2024-10-26T03:13:27.857861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vit_outputs = {x[\"image_id\"]: x[\"output\"] for x in vit_outputs}\n",
    "convnext_outputs = {x[\"image_id\"]: x[\"output\"] for x in convnext_outputs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70c66579",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-26T03:13:27.880050Z",
     "iopub.status.busy": "2024-10-26T03:13:27.879762Z",
     "iopub.status.idle": "2024-10-26T03:13:27.885045Z",
     "shell.execute_reply": "2024-10-26T03:13:27.884338Z"
    },
    "papermill": {
     "duration": 0.012439,
     "end_time": "2024-10-26T03:13:27.886818",
     "exception": false,
     "start_time": "2024-10-26T03:13:27.874379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_answers = []\n",
    "for image_id in vit_outputs.keys():\n",
    "    vit_output = vit_outputs[image_id]\n",
    "    convnext_output = convnext_outputs[image_id]\n",
    "    final_output = (vit_output + convnext_output) / 2\n",
    "    final_answers.append({\"image_id\": image_id, \"label\": np.argmax(final_output)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "633ead6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-26T03:13:27.896989Z",
     "iopub.status.busy": "2024-10-26T03:13:27.896712Z",
     "iopub.status.idle": "2024-10-26T03:13:27.902341Z",
     "shell.execute_reply": "2024-10-26T03:13:27.901541Z"
    },
    "papermill": {
     "duration": 0.012806,
     "end_time": "2024-10-26T03:13:27.904222",
     "exception": false,
     "start_time": "2024-10-26T03:13:27.891416",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(final_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63d301e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-26T03:13:27.914578Z",
     "iopub.status.busy": "2024-10-26T03:13:27.913979Z",
     "iopub.status.idle": "2024-10-26T03:13:27.928687Z",
     "shell.execute_reply": "2024-10-26T03:13:27.927768Z"
    },
    "papermill": {
     "duration": 0.021814,
     "end_time": "2024-10-26T03:13:27.930579",
     "exception": false,
     "start_time": "2024-10-26T03:13:27.908765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2216849948.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id  label\n",
       "0  2216849948.jpg      4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9293437a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-26T03:13:27.941518Z",
     "iopub.status.busy": "2024-10-26T03:13:27.940982Z",
     "iopub.status.idle": "2024-10-26T03:13:27.947853Z",
     "shell.execute_reply": "2024-10-26T03:13:27.947166Z"
    },
    "papermill": {
     "duration": 0.014121,
     "end_time": "2024-10-26T03:13:27.949682",
     "exception": false,
     "start_time": "2024-10-26T03:13:27.935561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b9dc1b",
   "metadata": {
    "papermill": {
     "duration": 0.004473,
     "end_time": "2024-10-26T03:13:27.958818",
     "exception": false,
     "start_time": "2024-10-26T03:13:27.954345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 1718836,
     "sourceId": 13836,
     "sourceType": "competition"
    },
    {
     "datasetId": 5938625,
     "sourceId": 9709258,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5940211,
     "sourceId": 9711322,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 47.710184,
   "end_time": "2024-10-26T03:13:31.037708",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-26T03:12:43.327524",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
