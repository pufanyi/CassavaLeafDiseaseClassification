{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import PIL\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import Compose, Normalize, Resize, CenterCrop, ToTensor\n",
    "\n",
    "id2label = {\n",
    "    0: \"Cassava Bacterial Blight (CBB)\",\n",
    "    1: \"Cassava Brown Streak Disease (CBSD)\",\n",
    "    2: \"Cassava Green Mottle (CGM)\",\n",
    "    3: \"Cassava Mosaic Disease (CMD)\",\n",
    "    4: \"Healthy\",\n",
    "}\n",
    "label2id = {\n",
    "    \"Cassava Bacterial Blight (CBB)\": 0,\n",
    "    \"Cassava Brown Streak Disease (CBSD)\": 1,\n",
    "    \"Cassava Green Mottle (CGM)\": 2,\n",
    "    \"Cassava Mosaic Disease (CMD)\": 3,\n",
    "    \"Healthy\": 4,\n",
    "}\n",
    "\n",
    "folder = Path(\"/kaggle/input/cassava-leaf-disease-classification/test_images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ViT full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/kaggle/input/sc4000-vit-large/models\"\n",
    "\n",
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    model_path,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True,\n",
    ")\n",
    "image_processor = AutoImageProcessor.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CassavaDatasetViT(Dataset):\n",
    "    def __init__(self, folder, image_processor):\n",
    "        self.folder = folder\n",
    "        self.image_processor = image_processor\n",
    "        self.image_paths = list(folder.glob(\"*\"))\n",
    "        self.image_mean, self.image_std = (\n",
    "            self.image_processor.image_mean,\n",
    "            self.image_processor.image_std,\n",
    "        )\n",
    "        size = self.image_processor.size[\"shortest_edge\"]\n",
    "        normalize = Normalize(mean=self.image_mean, std=self.image_std)\n",
    "        self.test_transforms = Compose(\n",
    "            [\n",
    "                Resize(size),\n",
    "                CenterCrop(size),\n",
    "                ToTensor(),\n",
    "                normalize,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        with PIL.Image.open(image_path) as image:\n",
    "            inputs = self.test_transforms(image.convert(\"RGB\"))\n",
    "        return inputs, image_path.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_outputs = []\n",
    "\n",
    "dataset = CassavaDatasetViT(folder, image_processor)\n",
    "dataloader = DataLoader(dataset, batch_size=16)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch, image_names in dataloader:\n",
    "        outputs = model(batch.to(device))\n",
    "        probabilities = F.softmax(outputs.logits, dim=-1).cpu().numpy()\n",
    "\n",
    "        submissions.extend(\n",
    "            {\"image_id\": image_name, \"output\": output}\n",
    "            for image_name, output in zip(image_names, probabilities)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvNeXt-V2 Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CassavaDatasetConvNeXtV2(Dataset):\n",
    "    def __init__(self, folder, image_processor):\n",
    "        self.folder = folder\n",
    "        self.image_processor = image_processor\n",
    "        self.image_paths = list(folder.glob(\"*\"))\n",
    "        self.image_mean, self.image_std = (\n",
    "            self.image_processor.image_mean,\n",
    "            self.image_processor.image_std,\n",
    "        )\n",
    "        size = self.image_processor.size[\"shortest_edge\"]\n",
    "        normalize = Normalize(mean=self.image_mean, std=self.image_std)\n",
    "        self.test_transforms = Compose(\n",
    "            [\n",
    "                Resize(size),\n",
    "                CenterCrop(size),\n",
    "                ToTensor(),\n",
    "                normalize,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        with PIL.Image.open(image_path) as image:\n",
    "            inputs = self.test_transforms(image.convert(\"RGB\"))\n",
    "        return inputs, image_path.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convnext_outputs = []\n",
    "\n",
    "dataset = CassavaDatasetConvNeXtV2(folder, image_processor)\n",
    "dataloader = DataLoader(dataset, batch_size=16)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch, image_names in dataloader:\n",
    "        outputs = model(batch.to(device))\n",
    "        # predictions = outputs.logits.argmax(dim=-1).cpu().numpy()\n",
    "        probabilities = F.softmax(outputs.logits, dim=-1).cpu().numpy()\n",
    "\n",
    "        convnext_outputs.extend(\n",
    "            {\"image_id\": image_name, \"output\": output}\n",
    "            for image_name, output in zip(image_names, probabilities)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_outputs = {x[\"image_id\"]: x[\"output\"] for x in vit_outputs}\n",
    "convnext_outputs = {x[\"image_id\"]: x[\"output\"] for x in convnext_outputs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_answers = []\n",
    "for image_id in vit_outputs.keys():\n",
    "    vit_output = vit_outputs[image_id]\n",
    "    convnext_output = convnext_outputs[image_id]\n",
    "    final_output = (vit_output + convnext_output) / 2\n",
    "    final_answers.append({\"image_id\": image_id, \"label\": np.argmax(final_output)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(submissions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sc4000",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
