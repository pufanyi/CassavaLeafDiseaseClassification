{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import PIL\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import Compose, Normalize, Resize, CenterCrop, ToTensor\n",
    "\n",
    "id2label = {\n",
    "    0: \"Cassava Bacterial Blight (CBB)\",\n",
    "    1: \"Cassava Brown Streak Disease (CBSD)\",\n",
    "    2: \"Cassava Green Mottle (CGM)\",\n",
    "    3: \"Cassava Mosaic Disease (CMD)\",\n",
    "    4: \"Healthy\",\n",
    "}\n",
    "label2id = {\n",
    "    \"Cassava Bacterial Blight (CBB)\": 0,\n",
    "    \"Cassava Brown Streak Disease (CBSD)\": 1,\n",
    "    \"Cassava Green Mottle (CGM)\": 2,\n",
    "    \"Cassava Mosaic Disease (CMD)\": 3,\n",
    "    \"Healthy\": 4,\n",
    "}\n",
    "\n",
    "folder = Path(\"/kaggle/input/cassava-leaf-disease-classification/test_images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ViT full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/kaggle/input/sc4000-vit-large/models\"\n",
    "\n",
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    model_path,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True,\n",
    ")\n",
    "image_processor = AutoImageProcessor.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CassavaDatasetViT(Dataset):\n",
    "    def __init__(self, folder, image_processor):\n",
    "        self.folder = folder\n",
    "        self.image_processor = image_processor\n",
    "        self.image_paths = list(folder.glob(\"*\"))\n",
    "        self.image_mean, self.image_std = (\n",
    "            self.image_processor.image_mean,\n",
    "            self.image_processor.image_std,\n",
    "        )\n",
    "        size = self.image_processor.size[\"shortest_edge\"]\n",
    "        normalize = Normalize(mean=self.image_mean, std=self.image_std)\n",
    "        self.test_transforms = Compose(\n",
    "            [\n",
    "                Resize(size),\n",
    "                CenterCrop(size),\n",
    "                ToTensor(),\n",
    "                normalize,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        with PIL.Image.open(image_path) as image:\n",
    "            inputs = self.test_transforms(image.convert(\"RGB\"))\n",
    "        return inputs, image_path.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_outputs = []\n",
    "\n",
    "dataset = CassavaDatasetViT(folder, image_processor)\n",
    "dataloader = DataLoader(dataset, batch_size=16)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch, image_names in dataloader:\n",
    "        outputs = model(batch.to(device))\n",
    "        probabilities = F.softmax(outputs.logits, dim=-1).cpu().numpy()\n",
    "\n",
    "        vit_outputs.extend(\n",
    "            {\"image_id\": image_name, \"output\": output}\n",
    "            for image_name, output in zip(image_names, probabilities)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_outputs = {x[\"image_id\"]: x[\"output\"] for x in vit_outputs}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvNeXt-V2 Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CassavaDatasetConvNeXtV2(Dataset):\n",
    "    def __init__(self, folder, image_processor):\n",
    "        self.folder = folder\n",
    "        self.image_processor = image_processor\n",
    "        self.image_paths = list(folder.glob(\"*\"))\n",
    "        self.image_mean, self.image_std = (\n",
    "            self.image_processor.image_mean,\n",
    "            self.image_processor.image_std,\n",
    "        )\n",
    "        size = self.image_processor.size[\"shortest_edge\"]\n",
    "        normalize = Normalize(mean=self.image_mean, std=self.image_std)\n",
    "        self.test_transforms = Compose(\n",
    "            [\n",
    "                Resize(size),\n",
    "                CenterCrop(size),\n",
    "                ToTensor(),\n",
    "                normalize,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        with PIL.Image.open(image_path) as image:\n",
    "            inputs = self.test_transforms(image.convert(\"RGB\"))\n",
    "        return inputs, image_path.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convnext_outputs = []\n",
    "\n",
    "dataset = CassavaDatasetConvNeXtV2(folder, image_processor)\n",
    "dataloader = DataLoader(dataset, batch_size=16)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch, image_names in dataloader:\n",
    "        outputs = model(batch.to(device))\n",
    "        # predictions = outputs.logits.argmax(dim=-1).cpu().numpy()\n",
    "        probabilities = F.softmax(outputs.logits, dim=-1).cpu().numpy()\n",
    "\n",
    "        convnext_outputs.extend(\n",
    "            {\"image_id\": image_name, \"output\": output}\n",
    "            for image_name, output in zip(image_names, probabilities)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convnext_outputs = {x[\"image_id\"]: x[\"output\"] for x in convnext_outputs}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CropNet (MobileNetV3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import from_pretrained_keras\n",
    "import tf_keras as keras\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "model = from_pretrained_keras(\"/kaggle/input/cropnet-mobilenetv3/models\")\n",
    "\n",
    "image_size = 224\n",
    "resize_scale = 1.5\n",
    "image_resize_shape = int(resize_scale * image_size)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_transforms = [\n",
    "    lambda img: tf.image.resize(\n",
    "        img, (image_resize_shape, image_resize_shape)\n",
    "    ),\n",
    "    lambda img: tf.image.resize_with_crop_or_pad(\n",
    "        img, target_height=image_size, target_width=image_size\n",
    "    ),\n",
    "    lambda img: img / 255.0,\n",
    "]\n",
    "\n",
    "def val_image_transforms(image):\n",
    "    for fn in val_transforms:\n",
    "        image = fn(image)\n",
    "    return image\n",
    "\n",
    "def open_image(path):\n",
    "    with Image.open(path) as image:\n",
    "        image = keras.utils.img_to_array(image)\n",
    "    return val_image_transforms(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = Path(\"/kaggle/input/cassava-leaf-disease-classification/test_images\")\n",
    "images = [(path.name, open_image(path)) for path in folder.glob(\"*\")]\n",
    "ids, inputs = map(list, zip(*images))\n",
    "\n",
    "input_data = tf.data.experimental.from_list(inputs).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.predict(input_data)[:, :-1].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropnet_outputs = [{\"image_id\": id, \"output\": output} for id, output in zip(ids, outputs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_answers = []\n",
    "for image_id in vit_outputs.keys():\n",
    "    vit_output = vit_outputs[image_id]\n",
    "    convnext_output = convnext_outputs[image_id]\n",
    "    cropnet_output = cropnet_outputs[image_id]\n",
    "    final_output = (vit_output + convnext_output + cropnet_output) / 3\n",
    "    final_answers.append({\"image_id\": image_id, \"label\": np.argmax(final_output)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(submissions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sc4000",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
