{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ed076b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T20:01:03.842863Z",
     "iopub.status.busy": "2024-10-27T20:01:03.842395Z",
     "iopub.status.idle": "2024-10-27T20:01:26.883599Z",
     "shell.execute_reply": "2024-10-27T20:01:26.882343Z"
    },
    "papermill": {
     "duration": 23.052582,
     "end_time": "2024-10-27T20:01:26.886470",
     "exception": false,
     "start_time": "2024-10-27T20:01:03.833888",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import PIL\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import Compose, Normalize, Resize, CenterCrop, ToTensor\n",
    "import gc\n",
    "\n",
    "id2label = {\n",
    "    0: \"Cassava Bacterial Blight (CBB)\",\n",
    "    1: \"Cassava Brown Streak Disease (CBSD)\",\n",
    "    2: \"Cassava Green Mottle (CGM)\",\n",
    "    3: \"Cassava Mosaic Disease (CMD)\",\n",
    "    4: \"Healthy\",\n",
    "}\n",
    "label2id = {\n",
    "    \"Cassava Bacterial Blight (CBB)\": 0,\n",
    "    \"Cassava Brown Streak Disease (CBSD)\": 1,\n",
    "    \"Cassava Green Mottle (CGM)\": 2,\n",
    "    \"Cassava Mosaic Disease (CMD)\": 3,\n",
    "    \"Healthy\": 4,\n",
    "}\n",
    "\n",
    "folder = Path(\"/kaggle/input/cassava-leaf-disease-classification/test_images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861c0d08",
   "metadata": {
    "papermill": {
     "duration": 0.005596,
     "end_time": "2024-10-27T20:01:26.898362",
     "exception": false,
     "start_time": "2024-10-27T20:01:26.892766",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ViT full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ee37212",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T20:01:26.912197Z",
     "iopub.status.busy": "2024-10-27T20:01:26.911455Z",
     "iopub.status.idle": "2024-10-27T20:01:31.899754Z",
     "shell.execute_reply": "2024-10-27T20:01:31.898377Z"
    },
    "papermill": {
     "duration": 4.998571,
     "end_time": "2024-10-27T20:01:31.902763",
     "exception": false,
     "start_time": "2024-10-27T20:01:26.904192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = \"/kaggle/input/sc4000-vit-large/models\"\n",
    "\n",
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    model_path,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True,\n",
    ")\n",
    "image_processor = AutoImageProcessor.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21dff6b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T20:01:31.917364Z",
     "iopub.status.busy": "2024-10-27T20:01:31.916953Z",
     "iopub.status.idle": "2024-10-27T20:01:31.926048Z",
     "shell.execute_reply": "2024-10-27T20:01:31.924668Z"
    },
    "papermill": {
     "duration": 0.019329,
     "end_time": "2024-10-27T20:01:31.928583",
     "exception": false,
     "start_time": "2024-10-27T20:01:31.909254",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CassavaDatasetViT(Dataset):\n",
    "    def __init__(self, folder, image_processor):\n",
    "        self.folder = folder\n",
    "        self.image_processor = image_processor\n",
    "        self.image_paths = list(folder.glob(\"*\"))\n",
    "        self.image_mean, self.image_std = (\n",
    "            self.image_processor.image_mean,\n",
    "            self.image_processor.image_std,\n",
    "        )\n",
    "        size = self.image_processor.size[\"height\"]\n",
    "        normalize = Normalize(mean=self.image_mean, std=self.image_std)\n",
    "        self.test_transforms = Compose(\n",
    "            [\n",
    "                Resize(size),\n",
    "                CenterCrop(size),\n",
    "                ToTensor(),\n",
    "                normalize,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        with PIL.Image.open(image_path) as image:\n",
    "            inputs = self.test_transforms(image.convert(\"RGB\"))\n",
    "        return inputs, image_path.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1858d2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T20:01:31.943335Z",
     "iopub.status.busy": "2024-10-27T20:01:31.942926Z",
     "iopub.status.idle": "2024-10-27T20:01:41.356098Z",
     "shell.execute_reply": "2024-10-27T20:01:41.354872Z"
    },
    "papermill": {
     "duration": 9.42401,
     "end_time": "2024-10-27T20:01:41.358860",
     "exception": false,
     "start_time": "2024-10-27T20:01:31.934850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vit_outputs = []\n",
    "\n",
    "dataset = CassavaDatasetViT(folder, image_processor)\n",
    "dataloader = DataLoader(dataset, batch_size=16)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch, image_names in dataloader:\n",
    "        outputs = model(batch.to(device))\n",
    "        probabilities = F.softmax(outputs.logits, dim=-1).cpu().numpy()\n",
    "\n",
    "        vit_outputs.extend(\n",
    "            {\"image_id\": image_name, \"output\": output}\n",
    "            for image_name, output in zip(image_names, probabilities)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d498ea9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T20:01:41.374291Z",
     "iopub.status.busy": "2024-10-27T20:01:41.373871Z",
     "iopub.status.idle": "2024-10-27T20:01:41.379392Z",
     "shell.execute_reply": "2024-10-27T20:01:41.378225Z"
    },
    "papermill": {
     "duration": 0.016158,
     "end_time": "2024-10-27T20:01:41.381545",
     "exception": false,
     "start_time": "2024-10-27T20:01:41.365387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vit_outputs = {x[\"image_id\"]: x[\"output\"] for x in vit_outputs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e100a12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T20:01:41.395778Z",
     "iopub.status.busy": "2024-10-27T20:01:41.395304Z",
     "iopub.status.idle": "2024-10-27T20:01:41.732603Z",
     "shell.execute_reply": "2024-10-27T20:01:41.731520Z"
    },
    "papermill": {
     "duration": 0.347954,
     "end_time": "2024-10-27T20:01:41.735507",
     "exception": false,
     "start_time": "2024-10-27T20:01:41.387553",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.cpu()\n",
    "del model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254ecae7",
   "metadata": {
    "papermill": {
     "duration": 0.005609,
     "end_time": "2024-10-27T20:01:41.747391",
     "exception": false,
     "start_time": "2024-10-27T20:01:41.741782",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ConvNeXt-V2 Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff952003",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T20:01:41.760829Z",
     "iopub.status.busy": "2024-10-27T20:01:41.760401Z",
     "iopub.status.idle": "2024-10-27T20:01:43.000688Z",
     "shell.execute_reply": "2024-10-27T20:01:42.999413Z"
    },
    "papermill": {
     "duration": 1.250151,
     "end_time": "2024-10-27T20:01:43.003341",
     "exception": false,
     "start_time": "2024-10-27T20:01:41.753190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = \"/kaggle/input/sc4000-convnext-v2-base/models\"\n",
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    model_path,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True,\n",
    ")\n",
    "image_processor = AutoImageProcessor.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43a9490f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T20:01:43.018487Z",
     "iopub.status.busy": "2024-10-27T20:01:43.017185Z",
     "iopub.status.idle": "2024-10-27T20:01:43.026024Z",
     "shell.execute_reply": "2024-10-27T20:01:43.024837Z"
    },
    "papermill": {
     "duration": 0.018939,
     "end_time": "2024-10-27T20:01:43.028408",
     "exception": false,
     "start_time": "2024-10-27T20:01:43.009469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CassavaDatasetConvNeXtV2(Dataset):\n",
    "    def __init__(self, folder, image_processor):\n",
    "        self.folder = folder\n",
    "        self.image_processor = image_processor\n",
    "        self.image_paths = list(folder.glob(\"*\"))\n",
    "        self.image_mean, self.image_std = (\n",
    "            self.image_processor.image_mean,\n",
    "            self.image_processor.image_std,\n",
    "        )\n",
    "        size = self.image_processor.size[\"shortest_edge\"]\n",
    "        normalize = Normalize(mean=self.image_mean, std=self.image_std)\n",
    "        self.test_transforms = Compose(\n",
    "            [\n",
    "                Resize(size),\n",
    "                CenterCrop(size),\n",
    "                ToTensor(),\n",
    "                normalize,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        with PIL.Image.open(image_path) as image:\n",
    "            inputs = self.test_transforms(image.convert(\"RGB\"))\n",
    "        return inputs, image_path.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "095806c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T20:01:43.042192Z",
     "iopub.status.busy": "2024-10-27T20:01:43.041796Z",
     "iopub.status.idle": "2024-10-27T20:01:46.410449Z",
     "shell.execute_reply": "2024-10-27T20:01:46.409370Z"
    },
    "papermill": {
     "duration": 3.378697,
     "end_time": "2024-10-27T20:01:46.413133",
     "exception": false,
     "start_time": "2024-10-27T20:01:43.034436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "convnext_outputs = []\n",
    "\n",
    "dataset = CassavaDatasetConvNeXtV2(folder, image_processor)\n",
    "dataloader = DataLoader(dataset, batch_size=16)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch, image_names in dataloader:\n",
    "        outputs = model(batch.to(device))\n",
    "        # predictions = outputs.logits.argmax(dim=-1).cpu().numpy()\n",
    "        probabilities = F.softmax(outputs.logits, dim=-1).cpu().numpy()\n",
    "\n",
    "        convnext_outputs.extend(\n",
    "            {\"image_id\": image_name, \"output\": output}\n",
    "            for image_name, output in zip(image_names, probabilities)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6540354a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T20:01:46.428610Z",
     "iopub.status.busy": "2024-10-27T20:01:46.428146Z",
     "iopub.status.idle": "2024-10-27T20:01:46.434170Z",
     "shell.execute_reply": "2024-10-27T20:01:46.433020Z"
    },
    "papermill": {
     "duration": 0.016178,
     "end_time": "2024-10-27T20:01:46.436540",
     "exception": false,
     "start_time": "2024-10-27T20:01:46.420362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "convnext_outputs = {x[\"image_id\"]: x[\"output\"] for x in convnext_outputs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd84b1d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T20:01:46.451977Z",
     "iopub.status.busy": "2024-10-27T20:01:46.451534Z",
     "iopub.status.idle": "2024-10-27T20:01:46.780885Z",
     "shell.execute_reply": "2024-10-27T20:01:46.779669Z"
    },
    "papermill": {
     "duration": 0.340236,
     "end_time": "2024-10-27T20:01:46.783547",
     "exception": false,
     "start_time": "2024-10-27T20:01:46.443311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.cpu()\n",
    "del model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf596918",
   "metadata": {
    "papermill": {
     "duration": 0.005636,
     "end_time": "2024-10-27T20:01:46.795272",
     "exception": false,
     "start_time": "2024-10-27T20:01:46.789636",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CropNet (MobileNetV3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdbab52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T20:01:46.809517Z",
     "iopub.status.busy": "2024-10-27T20:01:46.808529Z",
     "iopub.status.idle": "2024-10-27T20:01:52.875961Z",
     "shell.execute_reply": "2024-10-27T20:01:52.874770Z"
    },
    "papermill": {
     "duration": 6.077593,
     "end_time": "2024-10-27T20:01:52.878884",
     "exception": false,
     "start_time": "2024-10-27T20:01:46.801291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import from_pretrained_keras\n",
    "import tf_keras as keras\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "model = from_pretrained_keras(\"/kaggle/input/cropnet-mobilenetv3/models\")\n",
    "\n",
    "image_size = 224\n",
    "resize_scale = 1.5\n",
    "image_resize_shape = int(resize_scale * image_size)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b18aa1bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T20:01:52.893998Z",
     "iopub.status.busy": "2024-10-27T20:01:52.892985Z",
     "iopub.status.idle": "2024-10-27T20:01:52.900397Z",
     "shell.execute_reply": "2024-10-27T20:01:52.899217Z"
    },
    "papermill": {
     "duration": 0.017192,
     "end_time": "2024-10-27T20:01:52.902559",
     "exception": false,
     "start_time": "2024-10-27T20:01:52.885367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_transforms = [\n",
    "    lambda img: tf.image.resize(\n",
    "        img, (image_resize_shape, image_resize_shape)\n",
    "    ),\n",
    "    lambda img: tf.image.resize_with_crop_or_pad(\n",
    "        img, target_height=image_size, target_width=image_size\n",
    "    ),\n",
    "    lambda img: img / 255.0,\n",
    "]\n",
    "\n",
    "def val_image_transforms(image):\n",
    "    for fn in val_transforms:\n",
    "        image = fn(image)\n",
    "    return image\n",
    "\n",
    "def open_image(path):\n",
    "    with Image.open(path) as image:\n",
    "        image = keras.utils.img_to_array(image)\n",
    "    return val_image_transforms(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd43f8e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T20:01:52.917010Z",
     "iopub.status.busy": "2024-10-27T20:01:52.916018Z",
     "iopub.status.idle": "2024-10-27T20:01:52.974754Z",
     "shell.execute_reply": "2024-10-27T20:01:52.973531Z"
    },
    "papermill": {
     "duration": 0.06875,
     "end_time": "2024-10-27T20:01:52.977307",
     "exception": false,
     "start_time": "2024-10-27T20:01:52.908557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "folder = Path(\"/kaggle/input/cassava-leaf-disease-classification/test_images\")\n",
    "images = [(path.name, open_image(path)) for path in folder.glob(\"*\")]\n",
    "ids, inputs = map(list, zip(*images))\n",
    "\n",
    "input_data = tf.data.experimental.from_list(inputs).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c16deb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T20:01:52.991616Z",
     "iopub.status.busy": "2024-10-27T20:01:52.991151Z",
     "iopub.status.idle": "2024-10-27T20:02:00.493598Z",
     "shell.execute_reply": "2024-10-27T20:02:00.492099Z"
    },
    "papermill": {
     "duration": 7.513053,
     "end_time": "2024-10-27T20:02:00.496540",
     "exception": false,
     "start_time": "2024-10-27T20:01:52.983487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "outputs = model.predict(input_data)[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a74709c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T20:02:00.518237Z",
     "iopub.status.busy": "2024-10-27T20:02:00.517695Z",
     "iopub.status.idle": "2024-10-27T20:02:00.524254Z",
     "shell.execute_reply": "2024-10-27T20:02:00.523057Z"
    },
    "papermill": {
     "duration": 0.020314,
     "end_time": "2024-10-27T20:02:00.526805",
     "exception": false,
     "start_time": "2024-10-27T20:02:00.506491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cropnet_outputs = {id: output for id, output in zip(ids, outputs)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c8733f",
   "metadata": {
    "papermill": {
     "duration": 0.005959,
     "end_time": "2024-10-27T20:02:00.539313",
     "exception": false,
     "start_time": "2024-10-27T20:02:00.533354",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f989b656",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T20:02:00.553829Z",
     "iopub.status.busy": "2024-10-27T20:02:00.553281Z",
     "iopub.status.idle": "2024-10-27T20:02:00.561625Z",
     "shell.execute_reply": "2024-10-27T20:02:00.560310Z"
    },
    "papermill": {
     "duration": 0.018671,
     "end_time": "2024-10-27T20:02:00.564278",
     "exception": false,
     "start_time": "2024-10-27T20:02:00.545607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_answers = []\n",
    "for image_id in vit_outputs.keys():\n",
    "    vit_output = vit_outputs[image_id]\n",
    "    convnext_output = convnext_outputs[image_id]\n",
    "    cropnet_output = cropnet_outputs[image_id]\n",
    "    final_output = (vit_output + convnext_output + cropnet_output) / 3\n",
    "    final_answers.append({\"image_id\": image_id, \"label\": np.argmax(final_output)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9f855e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T20:02:00.584553Z",
     "iopub.status.busy": "2024-10-27T20:02:00.584027Z",
     "iopub.status.idle": "2024-10-27T20:02:00.595347Z",
     "shell.execute_reply": "2024-10-27T20:02:00.593912Z"
    },
    "papermill": {
     "duration": 0.024138,
     "end_time": "2024-10-27T20:02:00.597997",
     "exception": false,
     "start_time": "2024-10-27T20:02:00.573859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(final_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4376ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T20:02:00.613068Z",
     "iopub.status.busy": "2024-10-27T20:02:00.612511Z",
     "iopub.status.idle": "2024-10-27T20:02:00.635688Z",
     "shell.execute_reply": "2024-10-27T20:02:00.634430Z"
    },
    "papermill": {
     "duration": 0.033711,
     "end_time": "2024-10-27T20:02:00.638235",
     "exception": false,
     "start_time": "2024-10-27T20:02:00.604524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93d66cbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T20:02:00.653117Z",
     "iopub.status.busy": "2024-10-27T20:02:00.652597Z",
     "iopub.status.idle": "2024-10-27T20:02:00.664112Z",
     "shell.execute_reply": "2024-10-27T20:02:00.662895Z"
    },
    "papermill": {
     "duration": 0.022949,
     "end_time": "2024-10-27T20:02:00.667596",
     "exception": false,
     "start_time": "2024-10-27T20:02:00.644647",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138105c1",
   "metadata": {
    "papermill": {
     "duration": 0.008377,
     "end_time": "2024-10-27T20:02:00.686214",
     "exception": false,
     "start_time": "2024-10-27T20:02:00.677837",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 1718836,
     "sourceId": 13836,
     "sourceType": "competition"
    },
    {
     "datasetId": 5938625,
     "sourceId": 9709258,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5940211,
     "sourceId": 9711322,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5959843,
     "sourceId": 9737461,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 62.949779,
   "end_time": "2024-10-27T20:02:03.330915",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-27T20:01:00.381136",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
